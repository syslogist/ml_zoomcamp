{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8877e5e4",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "In this homework, we will use Credit Card Data from the previous homework.\n",
    "\n",
    "Note: sometimes your answer doesn't match one of the options exactly. That's fine. Select the option that's closest to your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0a0e13",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "-   Install Pipenv\n",
    "-   What's the version of pipenv you installed?\n",
    "-   Use `--version` to find out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0417dffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pipenv in c:\\users\\amiya\\anaconda3\\lib\\site-packages (2022.10.10)\n",
      "Requirement already satisfied: virtualenv-clone>=0.2.5 in c:\\users\\amiya\\anaconda3\\lib\\site-packages (from pipenv) (0.5.7)\n",
      "Requirement already satisfied: setuptools>=36.2.1 in c:\\users\\amiya\\anaconda3\\lib\\site-packages (from pipenv) (63.4.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\amiya\\anaconda3\\lib\\site-packages (from pipenv) (2022.9.24)\n",
      "Requirement already satisfied: virtualenv in c:\\users\\amiya\\anaconda3\\lib\\site-packages (from pipenv) (20.16.5)\n",
      "Requirement already satisfied: filelock<4,>=3.4.1 in c:\\users\\amiya\\anaconda3\\lib\\site-packages (from virtualenv->pipenv) (3.6.0)\n",
      "Requirement already satisfied: platformdirs<3,>=2.4 in c:\\users\\amiya\\anaconda3\\lib\\site-packages (from virtualenv->pipenv) (2.5.2)\n",
      "Requirement already satisfied: distlib<1,>=0.3.5 in c:\\users\\amiya\\anaconda3\\lib\\site-packages (from virtualenv->pipenv) (0.3.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install pipenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e9aef17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipenv, version 2022.10.10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pipenv --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4270c2",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "-   Use Pipenv to install Scikit-Learn version 1.0.2\n",
    "-   What's the first hash for scikit-learn you get in Pipfile.lock?\n",
    "\n",
    "Note: you should create an empty folder for homework and do it there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f72ade",
   "metadata": {},
   "source": [
    "**Answer:** 08ef968f6b72033c16c479c966bf37ccd49b06ea91b765e1cc27afefe723920b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb67fa4",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "We've prepared a dictionary vectorizer and a model.\n",
    "\n",
    "They were trained (roughly) using this code:\n",
    "```\n",
    "features = ['reports', 'share', 'expenditure', 'owner']\n",
    "dicts = df[features].to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X = dv.fit_transform(dicts)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear').fit(X, y)\n",
    "```\n",
    "Note: You don't need to train the model. This code is just for your reference.\n",
    "\n",
    "And then saved with Pickle. Download them:\n",
    "-   DictVectorizer\n",
    "-   LogisticRegression\n",
    "\n",
    "With `wget`:\n",
    "```\n",
    "PREFIX=https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/course-zoomcamp/cohorts/2022/05-deployment/homework\n",
    "wget $PREFIX/model1.bin\n",
    "wget $PREFIX/dv.bin\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca0895be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\amiya\\anaconda3\\lib\\site-packages (3.2)\n"
     ]
    }
   ],
   "source": [
    "# Using wget package as no 'wget' command is natively available in Windows\n",
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e8060df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved under model1.bin\n",
      "\n",
      "Saved under dv.bin\n"
     ]
    }
   ],
   "source": [
    "# Run once if files are not already downloaded\n",
    "\n",
    "import wget\n",
    "\n",
    "PREFIX=\"https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/course-zoomcamp/cohorts/2022/05-deployment/homework\"\n",
    "!python -m wget $PREFIX/model1.bin\n",
    "!python -m wget $PREFIX/dv.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddad7b35",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Let's use these models!\n",
    "-   Write a script for loading these models with pickle\n",
    "-   Score this client:\n",
    "\n",
    "`{\"reports\": 0, \"share\": 0.001694, \"expenditure\": 0.12, \"owner\": \"yes\"}`\n",
    "\n",
    "What's the probability that this client will get a credit card?\n",
    "-   0.162\n",
    "-   0.391\n",
    "-   0.601\n",
    "-   0.993\n",
    "\n",
    "If you're getting errors when unpickling the files, check their checksum:\n",
    "\n",
    "```\n",
    "$ md5sum model1.bin dv.bin\n",
    "3f57f3ebfdf57a9e1368dcd0f28a4a14  model1.bin\n",
    "6b7cded86a52af7e81859647fa3a5c2e  dv.bin\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc4514e",
   "metadata": {},
   "source": [
    "**Answer:** We first load the transformer (DictVectorizer) and the model (LogisticRegression) in the following cells. We then put the code in a script and later create a Flask based web app service in file `predict_prob.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4fe08c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13633618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amiya\\anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator LogisticRegression from version 1.0.2 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('model1.bin','rb') as f_model:\n",
    "    model = pickle.load(f_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ac0528a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amiya\\anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator DictVectorizer from version 1.0.2 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('dv.bin','rb') as f_dv:\n",
    "    dv = pickle.load(f_dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af1b59c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = {\"reports\": 0, \"share\": 0.001694, \"expenditure\": 0.12, \"owner\": \"yes\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05ebecf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.162"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dv.transform([client])\n",
    "y_prob_pred = model.predict_proba(X)[0,1]\n",
    "round(y_prob_pred,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b675f952",
   "metadata": {},
   "source": [
    "To avoid the warning and risk assocaiated with version difference in Scikit-learn (or any other package, for that matter), we will run the script in the right virtual environment created by `pipenv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3f6d5f",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Now let's serve this model as a web service\n",
    "-   Install Flask and gunicorn (or waitress, if you're on Windows)\n",
    "-   Write Flask code for serving the model\n",
    "-   Now score this client using `requests`:\n",
    "\n",
    "```\n",
    "url = \"YOUR_URL\"\n",
    "client = {\"reports\": 0, \"share\": 0.245, \"expenditure\": 3.438, \"owner\": \"yes\"}\n",
    "requests.post(url, json=client).json()\n",
    "```\n",
    "What's the probability that this client will get a credit card?\n",
    "\n",
    "-   0.274\n",
    "-   0.484\n",
    "-   0.698\n",
    "-   0.928"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8b7883",
   "metadata": {},
   "source": [
    "**Answer:** The Flask based web application has been created in the  `predict_prob.py` script, to run at port 9696 for all active network interface addresses (including loopback 127.0.0.1) using `waitress-serve` running under the virtual environment created with `pipenv` using the command:\n",
    "```\n",
    "pipenv run waitress-serve --listen=0.0.0.0:9696 predict_prob:app\n",
    "```\n",
    "The `Pipfile` and `Pipfile.lock` have been created earlier along with the virtual environment by running the following command:\n",
    "```\n",
    "pipenv install numpy, scikit-learn==1.0.2, flask, gunicorn, waitress\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc27d1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "136e2568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'card': True, 'card_probability': 0.9282218018527452}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The probability-predictor app must be started at port 9696 before executing this cell - else rqequest will time out.\n",
    "\n",
    "url = 'http://localhost:9696/predict'\n",
    "client = {\"reports\": 0, \"share\": 0.245, \"expenditure\": 3.438, \"owner\": \"yes\"}\n",
    "requests.post(url, json=client).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39573a5",
   "metadata": {},
   "source": [
    "## Docker\n",
    "\n",
    "Install [Docker](https://github.com/alexeygrigorev/mlbookcamp-code/blob/master/course-zoomcamp/05-deployment/06-docker.md). We will use it for the next two questions.\n",
    "\n",
    "For these questions, we prepared a base image: `svizor/zoomcamp-model:3.9.12-slim`. You'll need to use it (see Question 5 for an example).\n",
    "\n",
    "This image is based on `python:3.9.12-slim` and has a logistic regression model (a different one) as well a dictionary vectorizer inside.\n",
    "\n",
    "This is how the Dockerfile for this image looks like:\n",
    "```\n",
    "FROM python:3.9.12-slim\n",
    "WORKDIR /app\n",
    "COPY [\"model2.bin\", \"dv.bin\", \"./\"]\n",
    "```\n",
    "We already built it and then pushed it to [`svizor/zoomcamp-model:3.9.12-slim`](https://hub.docker.com/r/svizor/zoomcamp-model).\n",
    "\n",
    "Note: You don't need to build this docker image, it's just for your reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20606369",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Download the base image `svizor/zoomcamp-model:3.9.12-slim`. You can easily make it by using [docker pull](https://docs.docker.com/engine/reference/commandline/pull/) command.\n",
    "\n",
    "So what's the size of this base image?\n",
    "-   15 Mb\n",
    "-   125 Mb\n",
    "-   275 Mb\n",
    "-   415 Mb\n",
    "\n",
    "You can get this information when running `docker images` - it'll be in the \"SIZE\" column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7767a14b",
   "metadata": {},
   "source": [
    "**Answer:** 125 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0dac7b",
   "metadata": {},
   "source": [
    "## Dockerfile\n",
    "\n",
    "Now create your own Dockerfile based on the image we prepared.\n",
    "\n",
    "It should start like that:\n",
    "```\n",
    "FROM svizor/zoomcamp-model:3.9.12-slim\n",
    "# add your stuff here\n",
    "```\n",
    "Now complete it:\n",
    "-   Install all the dependencies form the Pipenv file\n",
    "-   Copy your Flask script\n",
    "-   Run it with Gunicorn\n",
    "\n",
    "After that, you can build your docker image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1fc4d1",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Let's run your docker container!\n",
    "\n",
    "After running it, score this client once again:\n",
    "```\n",
    "url = \"YOUR_URL\"\n",
    "client = {\"reports\": 0, \"share\": 0.245, \"expenditure\": 3.438, \"owner\": \"yes\"}\n",
    "requests.post(url, json=client).json()\n",
    "```\n",
    "What's the probability that this client will get a credit card now?\n",
    "-   0.289\n",
    "-   0.502\n",
    "-   0.769\n",
    "-   0.972"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba6f190",
   "metadata": {},
   "source": [
    "**Answer:** The Docker file, as well as the new Flask based script `predict_prob2.py` (to make use of the `model2.bin` already loaded in the base image) have been created. The new Docker image tagged as `card-predict` is built using the command\n",
    "```\n",
    "docker build -t card-predict .\n",
    "```\n",
    "and then run as a web service at port 9696 using the command\n",
    "```\n",
    "docker run -it --rm -p 9696:9696 card-predict:latest\n",
    "```\n",
    "Note: The `gunicorn`/`waitress` services should be stopped before running the Docker image which also spawns `gunicorn` based service at port 9696."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d2e8e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'card': True, 'card_probability': 0.7692649226628628}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Docker image must be started at port 9696 before executing this cell - else rqequest will time out.\n",
    "\n",
    "url = \"http://localhost:9696/predict\"\n",
    "client = {\"reports\": 0, \"share\": 0.245, \"expenditure\": 3.438, \"owner\": \"yes\"}\n",
    "requests.post(url, json=client).json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
